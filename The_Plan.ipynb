{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***GOAL: Wed. July 9 - Week 13-15, 18 Homework Complete***\n",
    "\n",
    "## July 2:\n",
    "* 19:00 - Dinner \n",
    "* 20:00 - **Week 13**\n",
    "* 21:00 - **Week 13**\n",
    "* 22:00 - **Week 13**\n",
    "## July 3:\n",
    "* 06:00 - Up and At 'em\n",
    "* 07:00 - Breakfast\n",
    "* 08:00 - **Week 14**\n",
    "* 09:00 - **Week 14**\n",
    "* 10:00 -  \n",
    "* 11:00 - **Week 14***\n",
    "* 12:00 - **Week 14**\n",
    "* 13:00 - Lunch\n",
    "* 14:00 - **Week 14**\n",
    "* 15:00 - **Week 14**\n",
    "* 16:00 - \n",
    "* 17:00 - Dinner\n",
    "* 18:00 - **Week 14**\n",
    "* 19:00 - **Week 14**\n",
    "* 20:00 - **Week 14**\n",
    "* 21:00 - Bed \n",
    "## July 4:\n",
    "* 06:00 - Up and At 'em\n",
    "* 07:00 - Breakfast\n",
    "* 08:00 - **Week 15**\n",
    "* 09:00 -\n",
    "* 10:00 - Out to Family Farm\n",
    "* 11:00 - Family Farm\n",
    "* 12:00 - Lunch\n",
    "* 13:00 - Home from Family Farm\n",
    "* 14:00 - **Week 15**\n",
    "* 15:00 - **Week 15**\n",
    "* 16:00 - \n",
    "* 17:00 - Dinner\n",
    "* 18:00 - **Week 15**\n",
    "* 19:00 - **Week 15** \n",
    "* 20:00 - **Week 15** \n",
    "* 21:00 - Bed\n",
    "## July 5:\n",
    "* 06:00 - Up and At 'em\n",
    "* 07:00 - Breakfast\n",
    "* 08:00 - **Week 16**\n",
    "* 09:00 - **Week 16**\n",
    "* 10:00 - \n",
    "* 11:00 - **Week 16**\n",
    "* 12:00 - **Week 16**\n",
    "* 13:00 - Lunch\n",
    "* 14:00 - **Week 16**\n",
    "* 15:00 - **Week 16**\n",
    "* 16:00 - \n",
    "* 17:00 - Dinner\n",
    "* 18:00 - **Week 16**\n",
    "* 19:00 - **Week 16** \n",
    "* 20:00 - **Week 16** \n",
    "* 21:00 - Bed\n",
    "## July 6:\n",
    "* 06:00 - Up and At 'em\n",
    "* 07:00 - Breakfast\n",
    "* 08:00 - **Week 18**\n",
    "* 09:00 - \n",
    "* 10:00 - **Week 18**\n",
    "* 11:00 - **Week 18**\n",
    "* 12:00 - Lunch\n",
    "* 13:00 - **Week 18**\n",
    "* 14:00 - **Week 18**\n",
    "* 15:00 - **Week 18**\n",
    "* 16:00 - \n",
    "* 17:00 - Dinner\n",
    "* 18:00 - **Week 18**\n",
    "* 19:00 - **Week 18**\n",
    "* 20:00 - **Week 18** \n",
    "* 21:00 - Bed\n",
    "## July 7:\n",
    "* 06:00 - Up and At 'em\n",
    "* 07:00 - Breakfast\n",
    "* 08:00 - **Week 18** \n",
    "* 09:00 - \n",
    "* 10:00 - **Week 18**\n",
    "* 11:00 - **Week 18**\n",
    "* 12:00 - Lunch\n",
    "* 13:00 - **Week 18**\n",
    "* 14:00 - **Week 18**\n",
    "* 15:00 - **Week 18**\n",
    "* 16:00 -  \n",
    "* 17:00 - Dinner\n",
    "* 17:30 - Class\n",
    "* 20:30 - Wind down \n",
    "* 21:00 - Bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 13: Machine Learning Supervised Learning\n",
    "##  * Goal: July 2 - End of Day\n",
    "## Assignment - In Class\n",
    "1. [Intro to Supervised Learning in Python](https://builtin.com/data-science/supervised-learning-python)\n",
    "2. Submit your group activity to Canvas using the git url! \n",
    "## Homework\n",
    "### a. Readings/Videos/DataCamp\n",
    "1. [Preprocessing for Machine Learning](https://learn.datacamp.com/courses/preprocessing-for-machine-learning-in-python) Complete 1-4\n",
    "2. [Supervised Learning in sklearn](https://learn.datacamp.com/courses/supervised-learning-with-scikit-learn) Complete 1-2\n",
    "### b. Optional Reading\n",
    "[Supervised learning in Sklearn](https://learn.datacamp.com/courses/supervised-learning-with-scikit-learn) 3-4\n",
    "### c. Notebook Instructions\n",
    "1. Create a markdown heading and explanation for each question in the supervised_learning.docx file under week 13.\n",
    "2. Put the code answer for each question under the markdown heading.\n",
    "3. Upload your completed notebook to github and submit the link to Canvas\n",
    "## Assignment - Notebook - Week 13\n",
    "1.\tDownload the dataset here: https://www.kaggle.com/sohier/calcofi and create one DataFrame for the bottle file and another for the cast file. Perform preprocessing on this dataset. You do not need to do all six types of preprocessing we discussed. For this dataset, 2-3 is all you need. \n",
    "2.\tCreate a correlation matrix to see how the features are correlated. Describe your findings. Pay particular attention to what is correlated with water temperature. \n",
    "3.\tPerform linear regression on the dataset to see if you can predict water temperature based on salinity. \n",
    "4.\tFind your mean squared error and R2 values. Be sure to indicate what these tell you. You can import these from sklearn.metrics . \n",
    "5.\tCreate a final plot of the relationship between water temperature and salinity. Be sure to show the values from the dataset in a scatter plot with a trend line that shows the predicted temperature values. \n",
    "6.\tDo some research on polynomial regression. Describe what it is any how it works in markdown. This article is useful https://machinelearningmastery.com/polynomial-features-transforms-for-machine-learning/ \n",
    "7.\tPerform polynomial regression on this same dataset. Train and validate your model as you did when you used linear regression. Mean squared error and R2 both apply here. \n",
    "8.\tCreate a final plot of the relationship between water temperature and salinity. Be sure to show the values from the dataset in a scatter plot with a trend line that shows the polynomial regression predicted temperature values. The resulting trend line should be curved. \n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 14 - Multiple Linear Regression and Logistic Regression\n",
    "## * Goal: July 7\n",
    "\n",
    "## Assignment - In Class\n",
    "1. [Logistic Regression](https://christophm.github.io/interpretable-ml-book/logistic.html) Read 4.2 on Logistic Regression\n",
    "2. Submit your group activity to Canvas using the git url! \n",
    "\n",
    "## Homework \n",
    "\n",
    "### a. Readings/Videos/DataCamp\n",
    "1. [Intermediate Regression with statsmodel](https://learn.datacamp.com/courses/intermediate-regression-with-statsmodels-in-python) Complete 1-4\n",
    "2. [Multiple Linear Regression](https://www.w3schools.com/python/python_ml_multiple_regression.asp) - this is another way to do multiple regression: different from the datacamp course but what we discussed in class. You can use either approach. \n",
    "3. [Preprocessing Reading](https://scikit-learn.org/stable/modules/preprocessing.html) - Please read this article to solidify your understanding of preprocessing\n",
    "\n",
    "### b. Optional Reading\n",
    "[Intro to Regression with Statsmodel](https://campus.datacamp.com/courses/introduction-to-regression-with-statsmodels-in-python)\n",
    "Some additional statistical concepts https://data-flair.training/blogs/python-statistics\n",
    "Read section 4.1 on Linear Regression https://christophm.github.io/interpretable-ml-book/limo.html \n",
    "Read https://www.investopedia.com/terms/m/mlr.asp on multiple linear regression\n",
    "\n",
    "### c. Notebook Instructions\n",
    "1. Create a markdown heading and explanation for each question in the regression_hw.docx file under week 14.\n",
    "2. Put the code answer for each question under the markdown heading.\n",
    "3. Upload your completed notebook to github and submit the link to Canvas.\n",
    "\n",
    "## Assignment - Notebook - Week 14\n",
    "1.\tPerform pre-processing on the full dataset here: https://www.kaggle.com/sohier/calcofi \n",
    "2.\tPerform feature selection (decide what columns should be included in your analysis). How did you figure out what features were important?\n",
    "3.\tPerform multiple linear regression on the dataset. Be sure to display the final resulting equation with the coefficients and intercept in markdown. \n",
    "4.\tWhich regression approach had the “best” performance? Be sure to compare it to what you did last week.\n",
    "5.\tWork with the diabetes dataset to perform multiple logistic regression. Look at the documentation for logistic regression in statsmodel and/or sklearn and see if you can tune the model performance based on available parameters. Please note: data scientists need to constantly learn new approaches to optimizing models. This is one way of doing that. \n",
    "6.\tWhat are the other ways to assess the performance of the model besides accuracy? What approach makes the most sense with the diabetes dataset? Why? \n",
    "7.\tIs the KNN model or the multiple logistic regression model more performant for the diabetes dataset? How can you tell? \n",
    "_________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 15 - Support Vector Machines, Oversampling, and Undersampling\n",
    "## Goal: July 7\n",
    "## Assignment - In Class \n",
    "1. [Oversampling and Undersampling](https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/)\n",
    "2. [SVM Sklearn Documentation](https://scikit-learn.org/stable/modules/svm.html)\n",
    "3. Submit your group activity to Canvas using the git url! \n",
    "## Homework\n",
    "### a. Readings/Videos/DataCamp\n",
    "[Linear Classifiers in sklearn](https://learn.datacamp.com/courses/linear-classifiers-in-python) Please complete 1-2\n",
    "### b. Optional Reading\n",
    "No optional readings this week. Make sure you understand very well what an SVM is and the kinds of problems it can be used to solve!\n",
    "### c. Notebook Instructions\n",
    "You do not have a notebook to complete this week. Your ETL projects are due next week and should be submitted under week 15 on canvas.\n",
    "## TURN IN ETL - Week 15\n",
    "___________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 16 - Decision Trees and ETL Code Reviews\n",
    "\n",
    "## Assignment - In Class\n",
    "1. [Decision Trees with python](https://datascience.foundation/sciencewhitepaper/understanding-decision-trees-with-python)  \n",
    "2. Submit your group activity to Canvas using the git url! \n",
    "\n",
    "## Homework \n",
    "\n",
    "### a. Readings/Videos/DataCamp\n",
    "1. [Linear Classifiers in sklearn](https://learn.datacamp.com/courses/linear-classifiers-in-python) Please complete 3-4\n",
    "2. [Machine Learning with Tree-Based Models](https://learn.datacamp.com/courses/machine-learning-with-tree-based-models-in-python) Please complete 1-2\n",
    "\n",
    "### b. Optional Reading\n",
    "[Gentle Introduction to Information Theory](https://machinelearningmastery.com/what-is-information-entropy/)\n",
    "[Information Theory](https://web.mit.edu/6.933/www/Fall2001/Shannon2.pdf) \n",
    "[Decision Tree Classification in Python](https://www.datacamp.com/community/tutorials/decision-tree-classification-python)\n",
    "[Decision Trees for Decision Making](https://hbr.org/1964/07/decision-trees-for-decision-making)\n",
    "\n",
    "### c. Notebook - Instructions\n",
    "1. Create a markdown heading and explanation for each question in the svm_over_under_sampling_hw.docx file under week 16.\n",
    "2. Put the code answer for each question under the markdown heading.\n",
    "3. Upload your completed notebook to github and submit the link to Canvas.\n",
    "\n",
    "## Assignment - Notebook - Week 16\n",
    "1.\tPerform combined over and undersampling on the diabetes dataset (use SMOTEENN). Explain how combined sampling works.\n",
    "2.\tComment on the performance of combined sampling vs the other approaches we have used for the diabetes dataset.\n",
    "3.\tWhat is outlier detection? Why is it useful? What methods can you use for outlier detection?\n",
    "4.\tPerform a linear SVM to predict credit approval (last column) using this dataset: https://archive.ics.uci.edu/ml/datasets/Statlog+%28Australian+Credit+Approval%29 . Make sure you look at the accompanying document that describes the data in the dat file. You will need to either convert this data to another file type or import the dat file to python. \n",
    "\n",
    "You can use this code, but otherwise you follow standard practices we have already used many times: <br>\n",
    "from sklearn.svm import SVC<br>\n",
    "classifier = SVC(kernel='linear')\n",
    "\n",
    "5.\tHow did the SVM model perform? Use a classification report. \n",
    "6.\tWhat kinds of jobs in data are you most interested in? Do some research on what is out there. Write about your thoughts in under 400 words. \n",
    "____________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 17 - Ensemble Learning - Random Forest\n",
    "\n",
    "## Assignment - In Class\n",
    "1. [ROC Curve](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc) \n",
    "2. Submit your group activity to Canvas using the git url! \n",
    "\n",
    "## Homework\n",
    "\n",
    "### a. Readings/Videos/DataCamp\n",
    "1. [Machine Learning with Tree-Based Models](https://learn.datacamp.com/courses/machine-learning-with-tree-based-models-in-python) Please complete 3-5\n",
    "2. [Random Forest Classifier in Python](https://www.datacamp.com/community/tutorials/random-forests-classifier-python) - This is a refresher on the basics we covered in class\n",
    "3. [Parallel Random Forest Paper](https://arxiv.org/pdf/1810.07748.pdf) - You do not need to understand 100% of this, but its important you know what the industry is doing\n",
    "4. [Intro to XGBoost](https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/) \n",
    "\n",
    "### b. Optional Reading\n",
    "[Ensemble Method - Bagging and boosting](https://quantdare.com/what-is-the-difference-between-bagging-and-boosting/)\n",
    "[Resampling Types](http://strata.uga.edu/8370/lecturenotes/resampling.html)\n",
    "[Complete Guide to Random Forest](https://builtin.com/data-science/random-forest-algorithm)\n",
    "[Random Forest in Python](https://machinelearningmastery.com/random-forest-ensemble-in-python/)\n",
    "[XGBoost Documentation](https://xgboost.readthedocs.io/en/latest/)\n",
    "\n",
    "### c. Notebook Instruction\n",
    "1. Create a markdown heading and explanation for each question in the tree_based_models_hw.docx file under week 17.\n",
    "2. Put the code answer for each question under the markdown heading.\n",
    "3. Upload your completed notebook to github and submit the link to Canvas.\n",
    "\n",
    "### You should start working on your final project now. At this point, you know enough to start \n",
    "\n",
    "## Assignment - Notebook - Week 17\n",
    "Using ONE of the following sources, complete the questions for only that source. \n",
    "Credit approval: https://archive.ics.uci.edu/ml/datasets/Statlog+%28Australian+Credit+Approval%29\n",
    "Cardiac Arrhythmia: https://archive.ics.uci.edu/ml/datasets/Arrhythmia \n",
    "Abalone age: https://archive.ics.uci.edu/ml/datasets/Abalone - this one is a bit harder since its not binary like the others, but if you really want to master these concepts, you should pick this one. \n",
    "Note: at least one of your models should have the most relevant performance metric above .90 . All performance metrics should be above .75 . You will partially be graded on model performance.\n",
    "1.\tPreprocess your dataset. Indicate which steps worked and which didn’t. Include your thoughts on why certain steps worked and certain steps didn’t. \n",
    "2.\tCreate a decision tree model tuned to the best of your abilities. Explain how you tuned it.\n",
    "3.\tCreate a random forest model tuned to the best of your abilities. Explain how you tuned it.\n",
    "4.\tCreate an xgboost model tuned to the best of your abilities. Explain how you tuned it. \n",
    "5.\tWhich model performed best? What is your performance metric? Why? \n",
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 18 - Intro to Neural Networks\n",
    "\n",
    "## Goal: July 7\n",
    "\n",
    "## In Class Assignment due Friday, July 2nd, 2021 @ 8pm\n",
    "1. TBD\n",
    "2. Submit your group activity to Canvas using the git url! \n",
    "\n",
    "## Homework due Wednesday, July 7, 2021 @ 5:30pm\n",
    "\n",
    "### a. Readings/Videos/DataCamp\n",
    "1. [Intro to Deep Learning](https://learn.datacamp.com/courses/introduction-to-deep-learning-in-python) please complete 1-4\n",
    "2. [Intro to TensorFlow](https://learn.datacamp.com/courses/introduction-to-tensorflow-in-python) please just complete 1\n",
    "\n",
    "### b. Optional Reading\n",
    "[PyTorch vs Keras vs TensorFlow](https://www.simplilearn.com/keras-vs-tensorflow-vs-pytorch-article)\n",
    "\n",
    "### c. Notebook Instructions\n",
    "1. Create a markdown heading and explanation for each question in the neural_networks_hw.docx file under week 17.\n",
    "2. Put the code answer for each question under the markdown heading.\n",
    "3. Upload your completed notebook to github and submit the link to Canvas.\n",
    "\n",
    "### Make sure you have picked your group for your final project. No issues if you want to mix them up. \n",
    "\n",
    "## Homework - Notebook - Week 18\n",
    "1.\tWhat is a neural network? What are the general steps required to build a neural network? \n",
    "2.\tGenerally, how do you check the performance of a neural network? Why? \n",
    "3.\tCreate a neural network using keras to predict the outcome of either of these datasets: \n",
    "Cardiac Arrhythmia: https://archive.ics.uci.edu/ml/datasets/Arrhythmia \n",
    "Abalone age: https://archive.ics.uci.edu/ml/datasets/Abalone\n",
    "4.\tWrite another algorithm to predict the same result as the previous question using either KNN or logistic regression.\n",
    "5.\tCreate a neural network using pytorch to predict the same result as question 3. \n",
    "6.\tCompare the performance of the neural networks to the other model you created. Which performed better? Why do you think that is?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
